name: Scrape

on:
  schedule:
    - cron: "0 */2 * * *"
  workflow_dispatch:
    inputs:
      site_id:
        description: "Optional site id"
        required: false
        type: string

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
      - name: Run scraper
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
        run: |
          if [ -n "${{ github.event.inputs.site_id }}" ]; then
            python backend/main.py "${{ github.event.inputs.site_id }}"
          else
            python backend/main.py
          fi